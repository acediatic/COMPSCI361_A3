{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0e4329b641bbdbd8e1182fbadc5ebb2e523e312e1f9373a057c466e1263c44057",
   "display_name": "Python 3.9.5 64-bit (windows store)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e4329b641bbdbd8e1182fbadc5ebb2e523e312e1f9373a057c466e1263c44057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "p()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"naivebayes-21\\\\trg.csv\"\n",
    "PATH_TO_TEST = \"naivebayes-21\\\\tst.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = []\n",
    "class_freq = defaultdict(lambda: 0)\n",
    "corpus = []\n",
    "\n",
    "with open(PATH_TO_DATA) as csv_file:\n",
    "    for line in csv_file:\n",
    "        line = line.replace('\\\"', '')\n",
    "\n",
    "        line_lst = line.split(',')\n",
    "        line_lst[-1] = line_lst[-1].replace('\\n', '')\n",
    "\n",
    "        class_freq[line_lst[1]] += 1 \n",
    "\n",
    "        corpus.append(line_lst[-1])\n",
    "\n",
    "        list_data.append(line_lst)\n",
    "\n",
    "\n",
    "full_csv_data = np.array(list_data)\n",
    "class_freq.pop('class')\n",
    "\n",
    "\n",
    "labels = class_freq.keys()\n",
    "headers = full_csv_data[0]\n",
    "data = np.asarray(full_csv_data[1:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "ABSTRT_I = 1\n",
    "LBL_I = 0\n",
    "\n",
    "class_to_int = {lbl:i for i, lbl in enumerate(labels)}\n",
    "int_to_class = {i:lbl for lbl, i in class_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_stratified_kfold_splits(data, k=10):\n",
    "    instances_of_class = dict()\n",
    "\n",
    "    # Create a dictionary with key being label, and the value being an array of instances of that class. \n",
    "    for i, label in enumerate(labels):\n",
    "        instances_of_class[label] = data[data[:, 0] == label]\n",
    "    \n",
    "    stratified_splits = dict()\n",
    "    \n",
    "    # Upsample to divisible by k\n",
    "    for class_label, class_instances in instances_of_class.items():\n",
    "        n = len(class_instances)\n",
    "        upsample_amt = k - (n % k)\n",
    "\n",
    "        random_indices = np.random.choice(class_instances[:, ABSTRT_I], size=upsample_amt, replace=False)\n",
    "        random_indices.resize((random_indices.shape[0], 2), refcheck=False)\n",
    "\n",
    "        random_indices[:, -1] = class_label\n",
    "\n",
    "        random_indices[:,[0, 1]] = random_indices[:,[1, 0]]\n",
    "\n",
    "        upsampled_class_instances = np.concatenate((class_instances, random_indices), 0)\n",
    "        assert len(upsampled_class_instances) % k == 0, \"num examples should be divisible by k\"\n",
    "\n",
    "        stratified_splits[class_label] = np.split(upsampled_class_instances, k)\n",
    "\n",
    "    for i in range(k):\n",
    "        kth_test_lst = [stratified_splits[label][i] for label in labels]\n",
    "        kth_train_lst = [stratified_splits[label][j] for label in labels for j in range(k) if j != i]\n",
    "\n",
    "        # Check golden rule preserved\n",
    "        for label in labels:\n",
    "            try:\n",
    "                kth_train_lst.index(stratified_splits[label][i])\n",
    "                assert False, \"GOLDEN RULE BROKEN!\" \n",
    "            except ValueError:\n",
    "                pass  \n",
    "    \n",
    "        kth_train_data = np.concatenate(kth_train_lst)\n",
    "        kth_test_data = np.concatenate(kth_test_lst)\n",
    "        np.random.shuffle(kth_train_data)\n",
    "        np.random.shuffle(kth_test_data)\n",
    "\n",
    "        yield kth_train_data, kth_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq_k_best(train, test = None, k = 500):\n",
    "    X_train, y_train = get_X_y(train)\n",
    "    if type(test) != type(None):\n",
    "        X_test, y_test = get_X_y(test)\n",
    "\n",
    "    train_words_i = get_word_indexes(X_train)\n",
    "\n",
    "    frequency_matrix_train = get_word_counts(X_train, train_words_i)\n",
    "    k_best_i = select_k_best(frequency_matrix_train, corr = False, k=k)\n",
    "    X_train = get_k_best(frequency_matrix_train, k_best_i)\n",
    "\n",
    "    if type(test) != type(None):\n",
    "        frequency_matrix_test = get_word_counts(X_test, train_words_i)\n",
    "        X_test = get_k_best(frequency_matrix_test, k_best_i)\n",
    "\n",
    "    if type(test) != type(None):\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        return X_train, y_train        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_indexes(all_words : set):\n",
    "    all_words_set = get_set_all_words(all_words)\n",
    "    return {word:i for i, word in enumerate(all_words_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_all_words(X):\n",
    "    all_words = set(word for i in range(len(X)) for word in X[i].split() if word) \n",
    "\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_counts(abstracts, word_indexes):    \n",
    "\n",
    "    word_frequencies_matrix = np.ones((len(abstracts), len(word_indexes)))\n",
    "\n",
    "    for i in range(len(abstracts)):\n",
    "        for word in abstracts[i].split():\n",
    "            try:\n",
    "                word_frequencies_matrix[i, word_indexes[word]] += 1\n",
    "            except KeyError:\n",
    "                # word not in training words\n",
    "                pass\n",
    "\n",
    "    return word_frequencies_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(arr, i):\n",
    "    ''' Calcualtes the correlation between one column (class) and the rest for the input matrix. Credit to FBruzzesi (https://stackoverflow.com/users/12411536/fbruzzesi)'''\n",
    "    mean_t = np.mean(arr, axis=0)\n",
    "    std_t = np.std(arr, axis=0)\n",
    "\n",
    "    mean_i = mean_t[i]\n",
    "    std_i = std_t[i]\n",
    "\n",
    "    mean_xy = np.mean(arr*arr[:,i][:,None], axis=0)\n",
    "\n",
    "    corr = (mean_xy - mean_i * mean_t)/(std_i * std_t)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_best(word_frequencies_matrix, corre=False, k=10):\n",
    "    if corre:\n",
    "        R = corr(word_frequencies_matrix, -1)\n",
    "        class_correlations = abs(R)\n",
    "        k_best_i = np.argpartition(class_correlations, -(k+1))[-(k+1):]\n",
    "        \n",
    "        # removes self column\n",
    "        k_best_i = k_best_i[:-1]\n",
    "\n",
    "    else:\n",
    "        class_correlations = word_frequencies_matrix.sum(axis=0)  \n",
    "        k_best_i = np.argpartition(class_correlations, -k)[-k:]\n",
    "    \n",
    "    return k_best_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_best(freq_mat, k_best_i):\n",
    "    X = freq_mat[:, k_best_i]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(combinedXy):\n",
    "    return combinedXy[:, ABSTRT_I], combinedXy[:, LBL_I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF\n",
    "def abstract_to_dict(abstract):\n",
    "    '''word:count for words in a particular abstract'''\n",
    "    abstractDict = defaultdict(lambda: 0)\n",
    "    for word in abstract.split(' '):\n",
    "        if word:\n",
    "            abstractDict[word] += 1 \n",
    "    return abstractDict \n",
    "\n",
    "def termFrequency(abstractDict : dict):\n",
    "    \"\"\"(# of repetitions of word in a document) / (# of words in a document)\"\"\"\n",
    "    termFrequencies = {}\n",
    "    numWords = len(abstractDict)\n",
    "    \n",
    "    for word, count in abstractDict.items():\n",
    "        termFrequencies[word] = count/numWords\n",
    "    return termFrequencies\n",
    "\n",
    "def get_inverse_document_frequency(abstract_dict_list : list):\n",
    "    \"\"\" used to calculate the weight of rare words across all documents in the corpus\n",
    "        idf(w) = log(num_docs/freq_word_all_docs)\"\"\"\n",
    "    idf = defaultdict(lambda: 0)\n",
    "    numAbstracts = len(abstract_dict_list)\n",
    "\n",
    "    # calculte number of docs containing word\n",
    "    for abstractDict in abstract_dict_list:\n",
    "        for word, count in abstractDict.items():\n",
    "            if count > 0:\n",
    "                idf[word] += 1 \n",
    "\n",
    "    from math import log10\n",
    "    for word, num_docs_containing_word in idf.items():\n",
    "        idf[word] = np.log(numAbstracts+1/num_docs_containing_word)+1\n",
    "\n",
    "    return idf\n",
    "\n",
    "def get_row_tfidf(tf, idf, word_indexes):\n",
    "    ''' num occurrences of word i in doc j * log(total docs / number of documents containing i) '''\n",
    "    row = np.zeros((1, len(word_indexes)))\n",
    "    for word, numOccurences in tf.items():\n",
    "        word_index = word_indexes[word]\n",
    "        row[0, word_index] = numOccurences*idf[word] \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfidf(X):\n",
    "    abstract_dict_list = []\n",
    "    term_frequency_lst = []\n",
    "    all_words = get_set_all_words(X)\n",
    "\n",
    "    new_X = np.zeros((len(X), len(all_words)))\n",
    "    word_indexes = {word: i for i, word in enumerate(all_words)}\n",
    "\n",
    "    for abstract in X:\n",
    "        abstract_dict = abstract_to_dict(abstract)\n",
    "        abstract_dict_list.append(abstract_dict)\n",
    "        term_frequency_lst.append(termFrequency(abstract_dict))\n",
    "\n",
    "    print(\"converted abstracts, calculating idf\")    \n",
    "    idf = get_inverse_document_frequency(abstract_dict_list)\n",
    "\n",
    "    print(\"calculating tfidf\")\n",
    "    for i,tf in enumerate(term_frequency_lst):\n",
    "        new_X[i] = get_row_tfidf(tf, idf, word_indexes)\n",
    "\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NaiveBayes():\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train: np.array):\n",
    "        self.num_classes = len(np.unique(y_train))\n",
    "        self.num_instances, self.num_features = X_train.shape\n",
    "\n",
    "        self.classes_to_int = {label:i for i, label in enumerate(np.unique(y_train))}\n",
    "        self.int_to_classes = {i:label for label, i in self.classes_to_int.items()}\n",
    "\n",
    "        y_train = np.asarray([self.classes_to_int[label] for label in y_train])\n",
    "\n",
    "        # initalises log cond probability array\n",
    "        self.log_cond_by_class = np.zeros((self.num_classes, self.num_features))\n",
    "\n",
    "        # initalises total_word_count_by_class array\n",
    "        self.total_word_count_by_class = np.zeros((self.num_classes, 1))\n",
    "\n",
    "        # initialises num examples by class\n",
    "        self.num_examples_in_class = np.zeros((self.num_classes, 1))\n",
    "\n",
    "        for c in range(self.num_classes):\n",
    "            # splits X into a list of arrays containing instances of a particular class\n",
    "            mask = (y_train == c)\n",
    "            instances_from_class = X_train[mask,:]\n",
    "\n",
    "            word_freq_for_class = np.sum(instances_from_class, axis=0) + self.alpha\n",
    "            assert 0 not in word_freq_for_class, 'word_freq_should all be > 0'\n",
    "\n",
    "            self.total_word_count_by_class[c] = np.sum(word_freq_for_class) \n",
    "            assert 0 not in self.total_word_count_by_class[c], 'total_word_count must all be > 0'\n",
    "\n",
    "            self.log_cond_by_class[c, :] = np.log(word_freq_for_class / self.total_word_count_by_class[c])\n",
    "\n",
    "            self.num_examples_in_class[c] = instances_from_class.shape[0]\n",
    "\n",
    "        total_word_count = np.sum(self.total_word_count_by_class)\n",
    "\n",
    "        self.prior_by_class = np.log(self.num_examples_in_class / self.num_instances)\n",
    "\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        num_instances = len(X_test)\n",
    "        y = np.zeros(num_instances)\n",
    "\n",
    "        for i in range(num_instances):\n",
    "            p_by_class = np.copy(self.prior_by_class)\n",
    "\n",
    "            for c in range(self.num_classes):\n",
    "                for word_i in range(X_test.shape[1]):\n",
    "                    log_cond_prob = self.log_cond_by_class[c][word_i]\n",
    "\n",
    "                    freq = X_test[i,word_i]\n",
    "                    p_by_class[c] += log_cond_prob * freq\n",
    "        \n",
    "            y[i] = np.argmax(p_by_class, axis = 0)[0]\n",
    "        return np.asarray([self.int_to_classes[c] for c in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesGaussian():\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train: np.array):\n",
    "        self.num_classes = len(np.unique(y_train))\n",
    "        self.num_instances, self.num_features = X_train.shape\n",
    "\n",
    "        self.classes_to_int = {label:i for i, label in enumerate(np.unique(y_train))}\n",
    "        self.int_to_classes = {i:label for label, i in self.classes_to_int.items()}\n",
    "\n",
    "        y_train = np.asarray([self.classes_to_int[label] for label in y_train])\n",
    "\n",
    "        # initalises log cond probability array\n",
    "        self.log_cond_by_class = np.zeros((self.num_classes, self.num_features))\n",
    "\n",
    "        # initalises total_word_count_by_class array\n",
    "        self.total_word_count_by_class = np.zeros((self.num_classes, 1))\n",
    "\n",
    "        # initialises num examples by class\n",
    "        self.num_examples_in_class = np.zeros((self.num_classes, 1))\n",
    "\n",
    "        for c in range(self.num_classes):\n",
    "            # splits X into a list of arrays containing instances of a particular class\n",
    "            instances_from_class = X_train[y_train == c]\n",
    "\n",
    "            word_freq_for_class = np.sum(instances_from_class, axis=0) + self.alpha\n",
    "            assert 0 not in word_freq_for_class, 'word_freq_should all be > 0'\n",
    "\n",
    "            self.total_word_count_by_class[c] = np.sum(word_freq_for_class) \n",
    "            assert 0 not in self.total_word_count_by_class[c], 'total_word_count must all be > 0'\n",
    "\n",
    "            self.log_cond_by_class[c, :] = np.log(word_freq_for_class / self.total_word_count_by_class[c])\n",
    "\n",
    "            self.num_examples_in_class[c] = instances_from_class.shape[0]\n",
    "\n",
    "        total_word_count = np.sum(self.total_word_count_by_class)\n",
    "\n",
    "        self.prior_by_class = np.log(self.num_examples_in_class / self.num_instances)\n",
    "\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        num_instances = len(X_test)\n",
    "        y = np.zeros(num_instances)\n",
    "\n",
    "        for i in range(num_instances):\n",
    "            p_by_class = np.copy(self.prior_by_class)\n",
    "\n",
    "            for c in range(self.num_classes):\n",
    "                for word_i in range(X_test.shape[1]):\n",
    "                    log_cond_prob = self.log_cond_by_class[c][word_i]\n",
    "\n",
    "                    freq = X_test[i,word_i]\n",
    "                    p_by_class[c] += log_cond_prob * freq\n",
    "        \n",
    "            y[i] = np.argmax(p_by_class, axis = 0)[0]\n",
    "        return np.asarray([self.int_to_classes[c] for c in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_test_classifier(X_train, y_train, X_test, y_test):\n",
    "    clf = NaiveBayes(alpha = 1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_y = clf.predict(X_test)\n",
    "\n",
    "    accuracy = np.count_nonzero(y_test[predict_y == y_test])/len(y_test)\n",
    "\n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_get_X_y(train, test, k=None):\n",
    "    X_train = train[:, ABSTRT_I]\n",
    "    y_train = train[:, LBL_I]\n",
    "\n",
    "    X_test = test[:, ABSTRT_I]\n",
    "    y_test = test[:, LBL_I]\n",
    "\n",
    "    X_train = calculate_tfidf(X_train)\n",
    "    X_test = calculate_tfidf(X_test) \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(k = 500, tfidf = False):\n",
    "    stratified_data = get_stratified_kfold_splits(data)\n",
    "    results = 0\n",
    "    count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            train, test = next(stratified_data)\n",
    "            print('-'*10, \"Run {}\".format(count+1), '-'*10)\n",
    "            print(\"Calculating Word Frequencies\")\n",
    "            feature_fn = tfidf_get_X_y if tfidf else word_freq_k_best \n",
    "            X_train, y_train, X_test, y_test = feature_fn(train, test, k=k)\n",
    "\n",
    "            print(\"Fitting and Testing.\")\n",
    "            accuracy = fit_and_test_classifier(X_train, y_train, X_test, y_test)\n",
    "            results += accuracy\n",
    "            print(\"Fold Accuracy: \", accuracy)\n",
    "            count += 1\n",
    "        except StopIteration:\n",
    "            break\n",
    "    \n",
    "    print('-'*10, \"Complete\", \"-\"*10)\n",
    "    print(\"Classifier Accuracy: \", results/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Run 1 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a3dce79b3fee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-613fd1700ca5>\u001b[0m in \u001b[0;36mcv\u001b[1;34m(k, tfidf)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting and Testing.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_and_test_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mresults\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fold Accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-6f59209f1e2c>\u001b[0m in \u001b[0;36mfit_and_test_classifier\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfit_and_test_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNaiveBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredict_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-3dcae90727c9>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_instances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_to_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "cv(1500, tfidf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Run 1 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8258706467661692\n",
      "---------- Run 2 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.7736318407960199\n",
      "---------- Run 3 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8034825870646766\n",
      "---------- Run 4 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.7985074626865671\n",
      "---------- Run 5 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.7711442786069652\n",
      "---------- Run 6 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8706467661691543\n",
      "---------- Run 7 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8109452736318408\n",
      "---------- Run 8 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8308457711442786\n",
      "---------- Run 9 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8208955223880597\n",
      "---------- Run 10 ----------\n",
      "Calculating Word Frequencies\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-131957913993>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-66-613fd1700ca5>\u001b[0m in \u001b[0;36mcv\u001b[1;34m(k, tfidf)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculating Word Frequencies\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mfeature_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_get_X_y\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword_freq_k_best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting and Testing.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-cbc618386a4d>\u001b[0m in \u001b[0;36mword_freq_k_best\u001b[1;34m(train, test, k)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mfrequency_matrix_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_word_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_words_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mk_best_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_k_best\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequency_matrix_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_k_best\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequency_matrix_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_best_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-d88aefb5a6ce>\u001b[0m in \u001b[0;36mget_k_best\u001b[1;34m(freq_mat, k_best_i)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_k_best\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_best_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfreq_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_best_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv(1500, tfidf = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tst_data():\n",
    "    with open(PATH_TO_TEST) as csv_file:\n",
    "        list_data = []\n",
    "        for line in csv_file:\n",
    "            line = line.replace('\\\"', '')\n",
    "\n",
    "            line_lst = line.split(',')\n",
    "            line_lst[-1] = line_lst[-1].replace('\\n', '')\n",
    "\n",
    "            corpus.append(line_lst[-1])\n",
    "\n",
    "            list_data.append(line_lst)\n",
    "\n",
    "        full_csv_data = np.array(list_data)\n",
    "        X_kaggle_test = full_csv_data[1:,1:]\n",
    "\n",
    "    return X_kaggle_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaggle_predictions():\n",
    "    clf = NaiveBayes(alpha = 1)\n",
    "\n",
    "    X_train, y_train = word_freq_k_best(data, None, 2000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_kaggle_test = get_tst_data()\n",
    "\n",
    "    predict_y = clf.predict(X_kaggle_test)\n",
    "\n",
    "    np.savetxt('predictions.csv', predict_y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U837'), dtype('<U837')) -> dtype('<U837')",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-8fe663f306a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_kaggle_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-95-00837ecbe603>\u001b[0m in \u001b[0;36mget_kaggle_predictions\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mX_kaggle_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tst_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpredict_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_kaggle_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predictions.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-3e550dacfd04>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                     \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                     \u001b[0mp_by_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlog_cond_prob\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_by_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U837'), dtype('<U837')) -> dtype('<U837')"
     ]
    }
   ],
   "source": [
    "get_kaggle_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}