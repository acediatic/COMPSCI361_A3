{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0e4329b641bbdbd8e1182fbadc5ebb2e523e312e1f9373a057c466e1263c44057",
   "display_name": "Python 3.9.5 64-bit (windows store)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e4329b641bbdbd8e1182fbadc5ebb2e523e312e1f9373a057c466e1263c44057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "COMPSCI361 A3 ASIN473\n",
    "\n",
    "## Pre-processing\n",
    "\n",
    "1.\n",
    "### Representation of Words\n",
    "\n",
    "I attempted representing words of the abstracts in two primary forms: TFID and word frequency.\n",
    "\n",
    "  1. Word Frequency\n",
    "\n",
    "Word frequency was the representation that I ended up using for my final prediction. This created an array of all words seen in the training data, and counted the frequency that word was seen in each particular abstract. When looking at validation data (in k-fold, or in the tst.csv), only those words that have been previously seen are considered, with the other ones skipped. This provides a matrix of frequencies which can then be passed to the later models.\n",
    "\n",
    "  1. TFIDF\n",
    "\n",
    "The Term-frequency, Inverse-Document-frequency representation is a weighted representation that takes the count of words as above (term frequency) but multiplies by the inverse frequency of that particular word across all the documents seen in training. This effectively weights each particular word for its uniqueness in the dataset, meaning it&#39;s ability to differentiate between different documents.\n",
    "\n",
    "1.\n",
    "### Data Processing\n",
    "\n",
    "In addition to the above word representation, a pearsons correlation was created to see if it could help in the selection of the k-best features. Though using a correlation should in theory lead to better results, in practice, selecting the words with the greatest frequency between documents yielded better results, and so this was chosen for the final prediction.\n",
    "\n",
    "## Naïve Bayes Implementation\n",
    "\n",
    "The implementation of Naïve Bayes follows that of the general theory. The model is fitted by generating priors, and probabilities for each word seen in the training data. Priors were equated to the number of instances seen from the class divided by the total number of instances. Probabilities for each class were calculated as the frequency of a particular word in a particular class divided by the total number of words (frequency included, non-unique) in a particular class.\n",
    "\n",
    "The log function was used to add probabilities (same effect and order preserved in log addition as in multiplication) in order to prevent underflow, when multiplying very small probabilities. The predicted class was still that with the greatest value, as a smaller likelihood becomes and increasingly negative number (order preservation).\n",
    "\n",
    "Prediction simply took the log probability of seeing each word in a particular class, added to the priors for that particular class, with the maximum returned as the predicted class.\n",
    "\n",
    "## Naïve Bayes Extensions\n",
    "\n",
    "| Class | Number of Examples from Class |\n",
    "| --- | --- |\n",
    "| A | 128 |\n",
    "| B | 1602 |\n",
    "| E | 2144 |\n",
    "| V | 126 |\n",
    "\n",
    "For the extension, I implemented the Naïve Bayes Complement classifier. According to SKLearn &quot;The Complement Naive Bayes classifier was designed to correct the &quot;severe assumptions&quot; made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets.&quot;. The dataset provide was relatively unbalanced (see table above) with a few thousand instances from two classes, and only a few hundred for the other two. The aforementioned imbalance results in the standard naïve bayes selecting poor weights for the decision boundary; the weights of these minority classes are shrunk. Additionally, the standard naïve bayes assumes independence of words, even when they are in fact (bound by natural language) inherently dependent. Using the complement class mitigates this issue by combing all other classes into the &#39;complement&#39; class, and taking the weighting of this class, rather than one class at a time.\n",
    "# 1\n",
    " Essentially, the class that is **least likely** to **not contain** the word is the one that is predicted by the Naïve Bayes Complement Classifier.\n",
    "\n",
    "The complement naïve bayes classifier was specifically chosen due to the advantages it presents on skewed datasets, such as the training one provided (see table above showing imbalance). Complement performs well in this scenario compared to the vanilla naïve bayes, as well as other extensions including multinomial, which suffers from predicting based off one class as describe above.\n",
    "\n",
    "## Performance Evaluation Methodology:\n",
    "\n",
    "1.\n",
    "### KFold\n",
    "\n",
    "To ensure a fair representation of model performance, K-fold Cross Validation was used. This gives a better estimate for model accuracy by evaluating over the whole training set multiple times. The K chosen for this purpose was 10; large enough for good accuracy, whilst being time conscious.\n",
    "\n",
    "1.\n",
    "### Stratified\n",
    "\n",
    "To account for the underrepresentation of some classes in the dataset, the aforementioned k-fold cross validation was also stratified. This ensured that there were representative percentages of each class within every fold, rather than some folds missing classes entirely as would be possible with the distribution of the dataset.\n",
    "\n",
    "## Model Performance (☹)\n",
    "\n",
    "1.\n",
    "### Standard\n",
    "\n",
    "The standard Naïve Bayes classifier had a training accuracy of ~3% when using tfidf, and an accuracy of ~84%. This was a reasonable accuracy, but is slightly less than could be expected from the dataset (~90%). Despite **lots** of testing, I couldn&#39;t seem to work out why ☹.\n",
    "\n",
    "The difference between these two methods can potentially be explained by the number of features. In tf-idf, no feature selection was used, unlike select-k-best for word frequency. The extra dimensionality of the tf-idf version of the data could have mislead the model, becoming overly biased towards each training fold, and not generalising very well.\n",
    "\n",
    "1.\n",
    "### Extended\n",
    "\n",
    "The extended naive bayes classifier had a training accuracy of ~3% percent when using tf-idf. This is definitely the result of implementation, but again, unfortunately, despite **many** hours, I could not determine the cause.\n",
    "\n",
    "The model had an accuracy of 46% when using the word frequency. This drop can only be explained by an incorrect implementation; there should have been improvement for the reasons described above.\n",
    "\n",
    "[1](#sdfootnote1anc) Source: http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"naivebayes-21\\\\trg.csv\"\n",
    "PATH_TO_TEST = \"naivebayes-21\\\\tst.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = []\n",
    "class_freq = defaultdict(lambda: 0)\n",
    "corpus = []\n",
    "\n",
    "with open(PATH_TO_DATA) as csv_file:\n",
    "    for line in csv_file:\n",
    "        line = line.replace('\\\"', '')\n",
    "\n",
    "        line_lst = line.split(',')\n",
    "        line_lst[-1] = line_lst[-1].replace('\\n', '')\n",
    "\n",
    "        class_freq[line_lst[1]] += 1 \n",
    "\n",
    "        corpus.append(line_lst[-1])\n",
    "\n",
    "        list_data.append(line_lst)\n",
    "\n",
    "\n",
    "full_csv_data = np.array(list_data)\n",
    "class_freq.pop('class')\n",
    "\n",
    "\n",
    "labels = class_freq.keys()\n",
    "headers = full_csv_data[0]\n",
    "data = np.asarray(full_csv_data[1:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "defaultdict(<function <lambda> at 0x0000020BABC22430>, {'B': 1602, 'A': 128, 'E': 2144, 'V': 126})\n"
     ]
    }
   ],
   "source": [
    "print(class_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "ABSTRT_I = 1\n",
    "LBL_I = 0\n",
    "\n",
    "class_to_int = {lbl:i for i, lbl in enumerate(labels)}\n",
    "int_to_class = {i:lbl for lbl, i in class_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_stratified_kfold_splits(data, k=10):\n",
    "    instances_of_class = dict()\n",
    "\n",
    "    # Create a dictionary with key being label, and the value being an array of instances of that class. \n",
    "    for i, label in enumerate(labels):\n",
    "        instances_of_class[label] = data[data[:, 0] == label]\n",
    "    \n",
    "    stratified_splits = dict()\n",
    "    \n",
    "    # Upsample to divisible by k\n",
    "    for class_label, class_instances in instances_of_class.items():\n",
    "        n = len(class_instances)\n",
    "        upsample_amt = k - (n % k)\n",
    "\n",
    "        random_indices = np.random.choice(class_instances[:, ABSTRT_I], size=upsample_amt, replace=False)\n",
    "        random_indices.resize((random_indices.shape[0], 2), refcheck=False)\n",
    "\n",
    "        random_indices[:, -1] = class_label\n",
    "\n",
    "        random_indices[:,[0, 1]] = random_indices[:,[1, 0]]\n",
    "\n",
    "        upsampled_class_instances = np.concatenate((class_instances, random_indices), 0)\n",
    "        assert len(upsampled_class_instances) % k == 0, \"num examples should be divisible by k\"\n",
    "\n",
    "        stratified_splits[class_label] = np.split(upsampled_class_instances, k)\n",
    "\n",
    "    for i in range(k):\n",
    "        kth_test_lst = [stratified_splits[label][i] for label in labels]\n",
    "        kth_train_lst = [stratified_splits[label][j] for label in labels for j in range(k) if j != i]\n",
    "\n",
    "        # Check golden rule preserved\n",
    "        for label in labels:\n",
    "            try:\n",
    "                kth_train_lst.index(stratified_splits[label][i])\n",
    "                assert False, \"GOLDEN RULE BROKEN!\" \n",
    "            except ValueError:\n",
    "                pass  \n",
    "    \n",
    "        kth_train_data = np.concatenate(kth_train_lst)\n",
    "        kth_test_data = np.concatenate(kth_test_lst)\n",
    "        np.random.shuffle(kth_train_data)\n",
    "        np.random.shuffle(kth_test_data)\n",
    "\n",
    "        yield kth_train_data, kth_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq_k_best(train, test = None, k = 500, kaggle = False):\n",
    "    X_train, y_train = get_X_y(train)\n",
    "    if type(test) != type(None):\n",
    "        if (kaggle):\n",
    "            X_test = test\n",
    "            y_test = None\n",
    "        else:\n",
    "            X_test, y_test = get_X_y(test)\n",
    "\n",
    "    train_words_i = get_word_indexes(X_train)\n",
    "\n",
    "    frequency_matrix_train = get_word_counts(X_train, train_words_i)\n",
    "    k_best_i = select_k_best(frequency_matrix_train, k=k)\n",
    "    X_train = get_k_best(frequency_matrix_train, k_best_i)\n",
    "\n",
    "    if type(test) != type(None):\n",
    "        frequency_matrix_test = get_word_counts(X_test, train_words_i)\n",
    "        X_test = get_k_best(frequency_matrix_test, k_best_i)\n",
    "\n",
    "    if type(test) != type(None):\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        return X_train, y_train        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_indexes(all_words : set):\n",
    "    all_words_set = get_set_all_words(all_words)\n",
    "    return {word:i for i, word in enumerate(all_words_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_all_words(X):\n",
    "    all_words = set(word for i in range(len(X)) for word in X[i].split() if word) \n",
    "\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_counts(abstracts, word_indexes):    \n",
    "\n",
    "    word_frequencies_matrix = np.ones((len(abstracts), len(word_indexes)))\n",
    "\n",
    "    for i in range(len(abstracts)):\n",
    "        for word in abstracts[i].split():\n",
    "            try:\n",
    "                word_frequencies_matrix[i, word_indexes[word]] += 1\n",
    "            except KeyError:\n",
    "                # word not in training words\n",
    "                pass\n",
    "\n",
    "    return word_frequencies_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(arr, i):\n",
    "    ''' Calcualtes the correlation between one column (class) and the rest for the input matrix. Credit to FBruzzesi (https://stackoverflow.com/users/12411536/fbruzzesi)'''\n",
    "    mean_t = np.mean(arr, axis=0)\n",
    "    std_t = np.std(arr, axis=0)\n",
    "\n",
    "    mean_i = mean_t[i]\n",
    "    std_i = std_t[i]\n",
    "\n",
    "    mean_xy = np.mean(arr*arr[:,i][:,None], axis=0)\n",
    "\n",
    "    corr = (mean_xy - mean_i * mean_t)/(std_i * std_t)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_best(word_frequencies_matrix, corre=False, k=10):\n",
    "    if corre:\n",
    "        R = corr(word_frequencies_matrix, -1)\n",
    "        class_correlations = abs(R)\n",
    "        k_best_i = np.argpartition(class_correlations, -(k+1))[-(k+1):]\n",
    "        \n",
    "        # removes self column\n",
    "        k_best_i = k_best_i[:-1]\n",
    "\n",
    "    else:\n",
    "        class_correlations = word_frequencies_matrix.sum(axis=0)  \n",
    "        k_best_i = np.argpartition(class_correlations, -k)[-k:]\n",
    "    \n",
    "    return k_best_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_best(freq_mat, k_best_i):\n",
    "    X = freq_mat[:, k_best_i]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(combinedXy):\n",
    "    return combinedXy[:, ABSTRT_I], combinedXy[:, LBL_I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF\n",
    "def abstract_to_dict(abstract):\n",
    "    '''word:count for words in a particular abstract'''\n",
    "    abstractDict = defaultdict(lambda: 0)\n",
    "    for word in abstract.split(' '):\n",
    "        if word:\n",
    "            abstractDict[word] += 1 \n",
    "    return abstractDict \n",
    "\n",
    "def termFrequency(abstractDict : dict):\n",
    "    \"\"\"(# of repetitions of word in a document) / (# of words in a document)\"\"\"\n",
    "    termFrequencies = {}\n",
    "    numWords = len(abstractDict)\n",
    "    \n",
    "    for word, count in abstractDict.items():\n",
    "        termFrequencies[word] = count/numWords\n",
    "    return termFrequencies\n",
    "\n",
    "def get_inverse_document_frequency(abstract_dict_list : list):\n",
    "    \"\"\" used to calculate the weight of rare words across all documents in the corpus\n",
    "        idf(w) = log(num_docs/freq_word_all_docs)\"\"\"\n",
    "    idf = defaultdict(lambda: 0)\n",
    "    numAbstracts = len(abstract_dict_list)\n",
    "\n",
    "    # calculte number of docs containing word\n",
    "    for abstractDict in abstract_dict_list:\n",
    "        for word, count in abstractDict.items():\n",
    "            if count > 0:\n",
    "                idf[word] += 1 \n",
    "\n",
    "    from math import log10\n",
    "    for word, num_docs_containing_word in idf.items():\n",
    "        idf[word] = np.log(numAbstracts+1/num_docs_containing_word)+1\n",
    "\n",
    "    return idf\n",
    "\n",
    "def get_row_tfidf(tf, idf, word_indexes):\n",
    "    ''' num occurrences of word i in doc j * log(total docs / number of documents containing i) '''\n",
    "    row = np.zeros((1, len(word_indexes)))\n",
    "    for word, numOccurences in tf.items():\n",
    "        word_index = word_indexes[word]\n",
    "        row[0, word_index] = numOccurences*idf[word] \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfidf(X):\n",
    "    abstract_dict_list = []\n",
    "    term_frequency_lst = []\n",
    "    all_words = get_set_all_words(X)\n",
    "\n",
    "    new_X = np.zeros((len(X), len(all_words)))\n",
    "    word_indexes = {word: i for i, word in enumerate(all_words)}\n",
    "\n",
    "    for abstract in X:\n",
    "        abstract_dict = abstract_to_dict(abstract)\n",
    "        abstract_dict_list.append(abstract_dict)\n",
    "        term_frequency_lst.append(termFrequency(abstract_dict))\n",
    "\n",
    "    print(\"converted abstracts, calculating idf\")    \n",
    "    idf = get_inverse_document_frequency(abstract_dict_list)\n",
    "\n",
    "    print(\"calculating tfidf\")\n",
    "    for i,tf in enumerate(term_frequency_lst):\n",
    "        new_X[i] = get_row_tfidf(tf, idf, word_indexes)\n",
    "\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes():\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train: np.array):\n",
    "        self.num_classes = len(np.unique(y_train))\n",
    "        self.num_instances, self.num_features = X_train.shape\n",
    "\n",
    "        self.classes_to_int = {label:i for i, label in enumerate(np.unique(y_train))}\n",
    "        self.int_to_classes = {i:label for label, i in self.classes_to_int.items()}\n",
    "\n",
    "        y_train = np.asarray([self.classes_to_int[label] for label in y_train])\n",
    "\n",
    "        # initalises log cond probability array\n",
    "        self.log_cond_by_class = np.zeros((self.num_classes, self.num_features))\n",
    "\n",
    "        # initalises total_word_count_by_class array\n",
    "        self.total_word_count_by_class = np.zeros((self.num_classes, 1))\n",
    "\n",
    "        # initialises num examples by class\n",
    "        self.num_examples_in_class = np.zeros((self.num_classes, 1))\n",
    "\n",
    "        for c in range(self.num_classes):\n",
    "            # splits X into a list of arrays containing instances of a particular class\n",
    "            mask = (y_train == c)\n",
    "            instances_from_class = X_train[mask,:]\n",
    "\n",
    "            word_freq_for_class = np.sum(instances_from_class, axis=0) + self.alpha\n",
    "            assert 0 not in word_freq_for_class, 'word_freq_should all be > 0'\n",
    "\n",
    "            self.total_word_count_by_class[c] = np.sum(word_freq_for_class) \n",
    "            assert 0 not in self.total_word_count_by_class[c], 'total_word_count must all be > 0'\n",
    "\n",
    "            self.log_cond_by_class[c, :] = np.log(word_freq_for_class / self.total_word_count_by_class[c])\n",
    "\n",
    "            self.num_examples_in_class[c] = instances_from_class.shape[0]\n",
    "\n",
    "        total_word_count = np.sum(self.total_word_count_by_class)\n",
    "\n",
    "        self.prior_by_class = np.log(self.num_examples_in_class / self.num_instances)\n",
    "\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        num_instances = len(X_test)\n",
    "        y = np.zeros(num_instances)\n",
    "\n",
    "        for i in range(num_instances):\n",
    "            p_by_class = np.copy(self.prior_by_class)\n",
    "\n",
    "            for c in range(self.num_classes):\n",
    "                for word_i in range(X_test.shape[1]):\n",
    "                    log_cond_prob = self.log_cond_by_class[c][word_i]\n",
    "\n",
    "                    freq = X_test[i,word_i]\n",
    "                    p_by_class[c] += log_cond_prob * freq\n",
    "        \n",
    "            y[i] = np.argmax(p_by_class, axis = 0)[0]\n",
    "        return np.asarray([self.int_to_classes[c] for c in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesComplement():\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train: np.array):\n",
    "        self.num_classes = len(np.unique(y_train))\n",
    "        self.num_instances, self.num_features = X_train.shape\n",
    "\n",
    "        self.classes_to_int = {label:i for i, label in enumerate(np.unique(y_train))}\n",
    "        self.int_to_classes = {i:label for label, i in self.classes_to_int.items()}\n",
    "\n",
    "        y_train = np.asarray([self.classes_to_int[label] for label in y_train])\n",
    "\n",
    "        # initalises log cond probability array\n",
    "        self.log_cond_by_class = np.zeros((self.num_classes, self.num_features))\n",
    "\n",
    "        # initalises total_word_count_by_class array\n",
    "        self.prior_by_class = np.zeros((self.num_classes, 1))\n",
    "\n",
    "        # initialises num examples by class\n",
    "        self.num_examples_in_class = np.zeros((self.num_classes, 1))\n",
    "\n",
    "        for c in range(self.num_classes):\n",
    "            # splits X into a list of arrays containing instances of a particular class\n",
    "            instances_from_class = X_train[y_train == c]\n",
    "\n",
    "            instances_from_other_class = X_train[y_train != c]\n",
    "\n",
    "            word_freq_for_class = np.sum(instances_from_class, axis=0) + self.alpha\n",
    "\n",
    "            word_freq_for_other_class = np.sum(instances_from_other_class, axis=0) + self.alpha\n",
    "\n",
    "            self.log_cond_by_class[c, :] = np.log(word_freq_for_other_class / word_freq_for_other_class.sum())\n",
    "\n",
    "            num_examples_in_class = instances_from_class.shape[0]\n",
    "\n",
    "            self.prior_by_class[c] = np.log(num_examples_in_class / self.num_instances)\n",
    "\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        num_instances = len(X_test)\n",
    "        y = np.zeros(num_instances)\n",
    "\n",
    "        for i in range(num_instances):\n",
    "            p_by_class = np.copy(self.prior_by_class)\n",
    "\n",
    "            for c in range(self.num_classes):\n",
    "                for word_i in range(X_test.shape[1]):\n",
    "                    log_cond_prob = self.log_cond_by_class[c][word_i]\n",
    "\n",
    "                    freq = X_test[i,word_i]\n",
    "                    p_by_class[c] += log_cond_prob * freq\n",
    "        \n",
    "            y[i] = np.argmin(p_by_class, axis = 0)[0]\n",
    "        return np.asarray([self.int_to_classes[c] for c in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_test_classifier(X_train, y_train, X_test, y_test, Complement=False):\n",
    "    if Complement:\n",
    "        clf = NaiveBayesComplement(alpha = 1)\n",
    "    else:\n",
    "        clf = NaiveBayes(alpha = 1)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_y = clf.predict(X_test)\n",
    "\n",
    "    accuracy = np.count_nonzero(y_test[predict_y == y_test])/len(y_test)\n",
    "\n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_get_X_y(train, test, k=None):\n",
    "    X_train = train[:, ABSTRT_I]\n",
    "    y_train = train[:, LBL_I]\n",
    "\n",
    "    X_test = test[:, ABSTRT_I]\n",
    "    y_test = test[:, LBL_I]\n",
    "\n",
    "    X_train = calculate_tfidf(X_train)\n",
    "    X_test = calculate_tfidf(X_test) \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(k = 500, tfidf = False, Complement = False):\n",
    "    stratified_data = get_stratified_kfold_splits(data)\n",
    "    results = 0\n",
    "    count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            train, test = next(stratified_data)\n",
    "            print('-'*10, \"Run {}\".format(count+1), '-'*10)\n",
    "            print(\"Calculating Word Frequencies\")\n",
    "            feature_fn = tfidf_get_X_y if tfidf else word_freq_k_best \n",
    "            X_train, y_train, X_test, y_test = feature_fn(train, test, k=k)\n",
    "\n",
    "            print(\"Fitting and Testing.\")\n",
    "            accuracy = fit_and_test_classifier(X_train, y_train, X_test, y_test, Complement=Complement)\n",
    "            results += accuracy\n",
    "            print(\"Fold Accuracy: \", accuracy)\n",
    "            count += 1\n",
    "        except StopIteration:\n",
    "            break\n",
    "    \n",
    "    print('-'*10, \"Complete\", \"-\"*10)\n",
    "    print(\"Classifier Accuracy: \", results/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Run 1 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03731343283582089\n",
      "---------- Run 2 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.12935323383084577\n",
      "---------- Run 3 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.0472636815920398\n",
      "---------- Run 4 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.05472636815920398\n",
      "---------- Run 5 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03731343283582089\n",
      "---------- Run 6 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.07960199004975124\n",
      "---------- Run 7 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.06716417910447761\n",
      "---------- Run 8 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03482587064676617\n",
      "---------- Run 9 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.029850746268656716\n",
      "---------- Run 10 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.04975124378109453\n",
      "---------- Complete ----------\n",
      "Classifier Accuracy:  0.05671641791044776\n"
     ]
    }
   ],
   "source": [
    "cv(2000, tfidf = True, Complement = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Run 1 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8258706467661692\n",
      "---------- Run 2 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.7761194029850746\n",
      "---------- Run 3 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8059701492537313\n",
      "---------- Run 4 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8009950248756219\n",
      "---------- Run 5 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.7736318407960199\n",
      "---------- Run 6 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8681592039800995\n",
      "---------- Run 7 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8134328358208955\n",
      "---------- Run 8 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8308457711442786\n",
      "---------- Run 9 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.8208955223880597\n",
      "---------- Run 10 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.7835820895522388\n",
      "---------- Complete ----------\n",
      "Classifier Accuracy:  0.8099502487562189\n"
     ]
    }
   ],
   "source": [
    "cv(2000, tfidf = False, Complement = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Run 1 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03980099502487562\n",
      "---------- Run 2 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.02736318407960199\n",
      "---------- Run 3 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03482587064676617\n",
      "---------- Run 4 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03233830845771144\n",
      "---------- Run 5 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03482587064676617\n",
      "---------- Run 6 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03482587064676617\n",
      "---------- Run 7 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.029850746268656716\n",
      "---------- Run 8 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.03233830845771144\n",
      "---------- Run 9 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.029850746268656716\n",
      "---------- Run 10 ----------\n",
      "Calculating Word Frequencies\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "converted abstracts, calculating idf\n",
      "calculating tfidf\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.01990049751243781\n",
      "---------- Complete ----------\n",
      "Classifier Accuracy:  0.03159203980099502\n"
     ]
    }
   ],
   "source": [
    "cv(2000, tfidf = True, Complement = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Run 1 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.4577114427860697\n",
      "---------- Run 2 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.417910447761194\n",
      "---------- Run 3 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.4552238805970149\n",
      "---------- Run 4 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.48009950248756217\n",
      "---------- Run 5 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.4154228855721393\n",
      "---------- Run 6 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.5099502487562189\n",
      "---------- Run 7 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.4527363184079602\n",
      "---------- Run 8 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.48009950248756217\n",
      "---------- Run 9 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.4925373134328358\n",
      "---------- Run 10 ----------\n",
      "Calculating Word Frequencies\n",
      "Fitting and Testing.\n",
      "Fold Accuracy:  0.4502487562189055\n",
      "---------- Complete ----------\n",
      "Classifier Accuracy:  0.4611940298507463\n"
     ]
    }
   ],
   "source": [
    "cv(2000, tfidf = False, Complement = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tst_data():\n",
    "    with open(PATH_TO_TEST) as csv_file:\n",
    "        list_data = []\n",
    "        for line in csv_file:\n",
    "            line = line.replace('\\\"', '')\n",
    "\n",
    "            line_lst = line.split(',')\n",
    "            line_lst[-1] = line_lst[-1].replace('\\n', '')\n",
    "\n",
    "            corpus.append(line_lst[-1])\n",
    "\n",
    "            list_data.append(line_lst)\n",
    "\n",
    "        full_csv_data = np.array(list_data)\n",
    "        X_kaggle_test = full_csv_data[1:,1:]\n",
    "\n",
    "    return X_kaggle_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaggle_predictions():\n",
    "    clf = NaiveBayes(alpha = 1)\n",
    "\n",
    "    X_kaggle_test = get_tst_data().flatten()\n",
    "\n",
    "    X_train, y_train, X_test, _ = word_freq_k_best(data, X_kaggle_test, 5000, True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predict_y = clf.predict(X_test)\n",
    "\n",
    "    return predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = get_kaggle_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.reshape((-1, 1))\n",
    "prediction_indicies = [i+1 for i in range(len(prediction))]\n",
    "\n",
    "prediction_indicies = np.asarray(prediction_indicies).reshape((-1, 1))\n",
    "\n",
    "prediction_w_i = np.concatenate((prediction_indicies, prediction), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_row = np.asarray([\"id\",\"class\"])\r\n",
    "header_row = header_row.reshape((1,2))\r\n",
    "\r\n",
    "prediction_all = np.concatenate((header_row, prediction_w_i), axis = 0)\r\n",
    "print(prediction_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predictions.csv', prediction_all, delimiter=',', fmt='%s')"
   ]
  }
 ]
}